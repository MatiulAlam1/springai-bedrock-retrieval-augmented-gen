# RAG with Spring AI, AWS Bedrock, and Qdrant

## Overview
The RAG Spring AI Bedrock project is a Spring Boot application that demonstrates a complete Retrieval-Augmented Generation (RAG) pipeline. It leverages the **Spring AI** framework to seamlessly integrate with large language models (LLMs) from **AWS Bedrock** and a vector database for efficient data retrieval.

This application allows users to send chat requests, which are then enriched with relevant context retrieved from **Qdrant**, our vector database. The combined prompt is then sent to **AWS Bedrock** to generate a response using the powerful **`anthropic.claude-3-5-sonnet-20241022-v2:0`** model.

## Project Structure
The project is organized as follows:

rag-spring-ai-bedrock
├── src
│   └── main
│       ├── java
│       │   └── com
│       │       └── example
│       │           └── rag
│       │               ├── RagApplication.java
│       │               ├── config
│       │               │   └── BedrockConfig.java
│       │               ├── controller
│       │               │   └── ChatController.java
│       │               ├── service
│       │               │   ├── EmbeddingService.java
│       │               │   ├── VectorStoreService.java
│       │               │   └── ChatService.java
│       │               └── model
│       │                   └── ChatRequest.java
│       └── resources
│           ├── application.yml
│           └── static
├── pom.xml
└── README.md

## Setup Instructions

1.  **Clone the Repository**
    ```bash
    git clone https://github.com/your-repo/rag-spring-ai-bedrock.git
    cd rag-spring-ai-bedrock
    ```

2.  **Run Qdrant Vector Database**
    Ensure you have a running instance of Qdrant. The easiest way to get started is with Docker:
    ```bash
    docker run -p 6333:6333 -p 6334:6334 qdrant/qdrant
    ```

3.  **Configure Application Properties**
    Update the `src/main/resources/application.yml` file with your AWS credentials, the Bedrock model ID, and the Qdrant connection details.

    ```yaml
    spring:
      ai:
        bedrock:
          anthropic:
            chat:
              model: anthropic.claude-3-5-sonnet-20241022-v2:0
          aws:
            region: us-east-1 # Or your preferred AWS region
            access-key: YOUR_AWS_ACCESS_KEY
            secret-key: YOUR_AWS_SECRET_KEY
        vector-store:
          qdrant:
            host: localhost
            port: 6333
    ```

4.  **Build the Project**
    Use Maven to build the project:
    ```bash
    mvn clean install
    ```

5.  **Run the Application**
    Start the Spring Boot application:
    ```bash
    mvn spring-boot:run
    ```

6.  **Access the API**
    The application exposes a REST API for chat interactions. You can send requests to the `/chat` endpoint to interact with the AI model.

## Usage Guidelines
- Send a `POST` request to the `/chat` endpoint with a JSON body containing your message.
- The application will first convert your message into an embedding and use it to search for relevant documents in the Qdrant vector store.
- The retrieved documents are then added as context to your original message and sent to the Anthropic Claude 3.5 Sonnet model via AWS Bedrock.
- The final, context-aware response generated by the model is returned.

## Dependencies
This project uses the following key dependencies:
-   **Spring Boot:** Core application framework.
-   **Spring AI:** For orchestrating the RAG pipeline and integrating AI components.
    -   `spring-ai-bedrock-starter`: For connecting to AWS Bedrock.
    -   `spring-ai-qdrant-store-starter`: For connecting to the Qdrant vector database.
-   **AWS SDK for Java:** Underpinning the communication with AWS services.
-   Other necessary libraries as defined in the `pom.xml` file.

## Contributing
Contributions are welcome! Please submit a pull request or open an issue for any enhancements or bug fixes.

## License
This project is licensed under the MIT License. See the `LICENSE` file for more details.
